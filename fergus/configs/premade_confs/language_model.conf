##############
## file stuff
#############
saving_prefix: language_model
######
train_filepath: wsj_flat_train.txt
dev_filepath: wsj_flat_dev.txt
test_filepath: wsj_flat_test.txt
########
embeddings_file: model_assets/lm/embeddings.npy
vocman_file: model_assets/lm/vocman.pkl
########
from_checkpoint: True

##########
## set in training
###########
max_sequence_len: -1
vocab_size: 0

###### 
## training parameters
#####
num_epochs: 1500
max_grad_norm: 10
max_grad_value: 5.0
LR: 0.01
max_sentence_length: 65
frequency_cutoff: 5
size_cutoff: null
load_data: False

#### ###############
## model parameters
#########
embedding_size: 300
rnn_size: 368
batch_size: 32
num_lstms: 2
p_emb_dropout: 0.5
p_W_dropout: 0.5
p_U_dropout: 0.5
p_dense_dropout: 0.5
weight_decay: 1e-8

#########
## logger stuff
##########
disable_logger: False
